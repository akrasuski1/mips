{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Alsh data: http://manikvarma.org/downloads/XC/XMLRepository.html \n",
    "\n",
    "renamed to train.txt and test.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('./faiss/'))\n",
    "sys.path.append(os.path.abspath('./python/'))\n",
    "\n",
    "from experiments.data import get_data\n",
    "from misc.utils import to_ft, load_sift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-28 23:15:49,962 - root - INFO - Data not found or `force` flag was passed, I'm going to prepare it and store at ./data/LSHTC/X_train.csr.npz.\n",
      "2017-11-28 23:21:12,478 - root - INFO - Data not found or `force` flag was passed, I'm going to prepare it and store at ./data/LSHTC/X_test.csr.npz.\n"
     ]
    }
   ],
   "source": [
    "X, Y, words_mask, labels_mask = get_data('./data/LSHTC', 'train', min_words=3, min_labels=3)\n",
    "to_ft(X, Y, './data/LSHTC-FT/train.txt')\n",
    "\n",
    "X, Y, *_ = get_data('./data/LSHTC', 'test', words_mask=words_mask, labels_mask=labels_mask)\n",
    "to_ft(X, Y, './data/LSHTC-FT/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [
     0,
     7,
     22
    ]
   },
   "outputs": [],
   "source": [
    "def make_cmd(*args, **kwargs):\n",
    "    args = ' '.join(args)\n",
    "    opts = ' '.join(f'-{k} {v}' for k, v in kwargs.items())\n",
    "    cmd  = f'./fastText/fasttext {args} {opts}'\n",
    "    \n",
    "    return cmd.split()\n",
    "\n",
    "train_cmd = make_cmd('supervised', \n",
    "                     input         = './data/LSHTC-FT/train.txt',\n",
    "                     output        = './data/LSHTC-FT/model.ft',\n",
    "                     minCount      = 5,\n",
    "                     minCountLabel = 5,\n",
    "                     lr            = 0.1,\n",
    "                     lrUpdateRate  = 100,\n",
    "                     dim           = 256,\n",
    "                     ws            = 5,\n",
    "                     epoch         = 25,\n",
    "                     neg           = 25,\n",
    "                     loss          = 'ns',\n",
    "                     thread        = 8,\n",
    "                     saveOutput    = 1)\n",
    "\n",
    "generate_cmd = make_cmd('to-fvecs',\n",
    "                        './data/LSHTC-FT/model.ft.bin',\n",
    "                        './data/LSHTC-FT/test.txt',\n",
    "                        './data/LSHTC-FT/fvecs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.call(train_cmd)\n",
    "subprocess.call(generate_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('./faiss/'))\n",
    "sys.path.append(os.path.abspath('./python/'))\n",
    "\n",
    "import faiss\n",
    "import mips\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from experiments.data import get_data\n",
    "from misc.utils import to_ft, load_sift\n",
    "\n",
    "import uuid\n",
    "import time, datetime\n",
    "\n",
    "from contextlib import contextmanager\n",
    "import json\n",
    "\n",
    "from tinydb import TinyDB, where\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     1,
     12,
     19,
     29,
     53,
     57,
     68,
     84
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer():\n",
    "    class Clock:\n",
    "        elapsed = 0\n",
    "        \n",
    "    t0 = time.time()\n",
    "    \n",
    "    yield Clock\n",
    "    \n",
    "    Clock.elapsed = time.time() - t0\n",
    "\n",
    "\n",
    "def search(idx, data, k):\n",
    "    D, I = idx.search(data, k)\n",
    "    D, I = D.reshape(-1, k), I.reshape(-1, k)\n",
    "    \n",
    "    return D, I\n",
    "\n",
    "\n",
    "def compute_p1(G, I):\n",
    "    p1 = 0.\n",
    "    for i, item in enumerate(I):\n",
    "        p1 += float(int(item) in G[i])\n",
    "\n",
    "    p1 /= len(G)\n",
    "    \n",
    "    return p1\n",
    "\n",
    "\n",
    "def test_idx(IdxClass, params, xb, xq, G, k=100):\n",
    "    \n",
    "    try:\n",
    "\n",
    "        idx = IdxClass(**params)\n",
    "\n",
    "        with timer() as train_t:\n",
    "            idx.train(xb)\n",
    "            idx.add(xb)\n",
    "\n",
    "        with timer() as search_t:\n",
    "            _, I = search(idx, xq, k)\n",
    "\n",
    "        p1 = compute_p1(G, I[:, 0])\n",
    "\n",
    "        report = make_report(IdxClass, params, p1, train_t.elapsed, search_t.elapsed)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print('FAILED: ' + str(e))\n",
    "        report = str(e)\n",
    "\n",
    "    return report\n",
    "\n",
    "\n",
    "def now():\n",
    "    return datetime.datetime.fromtimestamp(time.time()).strftime(\"%d-%m-%y %H:%M:%S\")\n",
    "\n",
    "\n",
    "def make_report(IdxClass, params, p1, train_t, search_t):\n",
    "    return {\n",
    "        'ID': uuid.uuid4().hex,\n",
    "        'algo': IdxClass.__name__,\n",
    "        'params': params,\n",
    "        'p1': p1,\n",
    "        'train_t': train_t,\n",
    "        'search_t': search_t\n",
    "    }\n",
    "\n",
    "\n",
    "def add_result(r):\n",
    "    \n",
    "    if isinstance(r, dict):\n",
    "        algo, params, p1, t = r['algo'], r['params'], r['p1'], r['search_t']\n",
    "        rep = f'(params={params}, p1={p1:.2f}, t={t:.2f})'\n",
    "    else:\n",
    "        rep = r\n",
    "    \n",
    "    logger.info(f'Adding: {rep}')\n",
    "    \n",
    "    def result_adder(doc):\n",
    "        doc['results'].append(r)\n",
    "        \n",
    "    DB.update(result_adder, where('ID') == ID)\n",
    "\n",
    "\n",
    "def test(IdxClass, **params):\n",
    "    return test_idx(IdxClass, params, xb, xq, G, k=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !rm ./data/results/ad-hoc-db.json\n",
    "DB = TinyDB('./data/results/ad-hoc-db.json')\n",
    "ID = uuid.uuid4().hex\n",
    "\n",
    "info = dict(\n",
    "    ID = ID,\n",
    "    name = 'ad-hoc-results',\n",
    "    date = now(),\n",
    "    results = []\n",
    ")\n",
    "\n",
    "DB.insert(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT = 250_000\n",
    "\n",
    "# LOAD --------------\n",
    "\n",
    "xq = load_sift('./data/LSHTC-FT/fvecs.hid.fvecs', dtype=np.float32)\n",
    "xb = load_sift('./data/LSHTC-FT/fvecs.wo.fvecs', dtype=np.float32)\n",
    "\n",
    "_n, d, c = xq.shape[0], xq.shape[1], xb.shape[0]\n",
    "\n",
    "# LIMIT --------------\n",
    "\n",
    "inds = np.random.choice(np.arange(_n), LIMIT, replace=False)\n",
    "xq   = xq[inds, :]\n",
    "\n",
    "xq = np.copy(np.ascontiguousarray(xq), order='C')\n",
    "xb = np.copy(np.ascontiguousarray(xb), order='C')\n",
    "\n",
    "n = xq.shape[0]\n",
    "\n",
    "# GT --------------\n",
    "\n",
    "G = []\n",
    "for line in open('./data/LSHTC-FT/fvecs.labels.txt'):\n",
    "    G.append({int(y) for y in line.split()})\n",
    "G = [G[idx] for idx in inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-29 03:35:45,205 - root - INFO - Loaded dataset of 576_246, 256-dimensionsl queries (examples), but limiting to 250_000 queries\n",
      "2017-11-29 03:35:45,205 - root - INFO - The dataset contains 163_679 classes, and more than one class can be positive\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Loaded dataset of {_n:_}, {d:_}-dimensionsl queries (examples), but limiting to {LIMIT:_} queries\")\n",
    "logger.info(f\"The dataset contains {c:_} classes, and more than one class can be positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IVFIndex:\n",
    "    def __init__(self, d, size, nprobe):\n",
    "        self.index = faiss.index_factory(d, f\"IVF{size},Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "        self.index.nprobe = nprobe\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self.index, name)\n",
    "    \n",
    "    \n",
    "class KMeansIndex:\n",
    "    def __init__(self, d, layers, nprobe, m, U):\n",
    "        self.aug = mips.MipsAugmentationShrivastava(d, m, U)\n",
    "        self.index = mips.IndexHierarchicKmeans(d, layers, nprobe, self.aug)\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self.index, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Round 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IVF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-29 03:36:18,262 - root - INFO - Adding: (params={'d': 256, 'size': 4096, 'nprobe': 1}, p1=0.20, t=2.22)\n",
      "2017-11-29 03:36:41,395 - root - INFO - Adding: (params={'d': 256, 'size': 4096, 'nprobe': 16}, p1=0.26, t=8.90)\n",
      "2017-11-29 03:37:14,259 - root - INFO - Adding: (params={'d': 256, 'size': 4096, 'nprobe': 32}, p1=0.26, t=17.66)\n",
      "2017-11-29 03:38:04,275 - root - INFO - Adding: (params={'d': 256, 'size': 4096, 'nprobe': 64}, p1=0.26, t=35.05)\n",
      "2017-11-29 03:39:23,187 - root - INFO - Adding: (params={'d': 256, 'size': 4096, 'nprobe': 128}, p1=0.26, t=63.53)\n"
     ]
    }
   ],
   "source": [
    "for size in [4096]:\n",
    "    for nprobe in [1, 16, 32, 64, 128]:\n",
    "        add_result(\n",
    "            test(\n",
    "                IVFIndex, d=d, size=size, nprobe=nprobe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-29 03:39:58,857 - root - INFO - Adding: (params={'d': 256, 'layers': 2, 'nprobe': 1, 'm': 5, 'U': 0.85}, p1=0.10, t=3.19)\n",
      "2017-11-29 03:41:06,709 - root - INFO - Adding: (params={'d': 256, 'layers': 2, 'nprobe': 16, 'm': 5, 'U': 0.85}, p1=0.23, t=28.02)\n",
      "2017-11-29 03:42:24,757 - root - INFO - Adding: (params={'d': 256, 'layers': 2, 'nprobe': 32, 'm': 5, 'U': 0.85}, p1=0.25, t=46.81)\n",
      "2017-11-29 03:44:53,502 - root - INFO - Adding: (params={'d': 256, 'layers': 2, 'nprobe': 64, 'm': 5, 'U': 0.85}, p1=0.25, t=117.94)\n"
     ]
    }
   ],
   "source": [
    "for layers in [2]:\n",
    "    for nprobe in [1, 16, 32, 64, 128]:\n",
    "        add_result(\n",
    "            test(\n",
    "                KMeansIndex, d=d, layers=layers, nprobe=nprobe, m=5, U=0.85))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Round 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IVF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for size in [4096]:\n",
    "    for nprobe in [256, 512]:\n",
    "        add_result(\n",
    "            test(\n",
    "                IVFIndex, d=d, size=size, nprobe=nprobe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layers in [2]:\n",
    "    for nprobe in [256, 512]:\n",
    "        add_result(\n",
    "            test(\n",
    "                KMeansIndex, d=d, layers=layers, nprobe=nprobe, m=5, U=0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layers in [3]:\n",
    "    for nprobe in [1, 16, 32, 64, 128]:\n",
    "        add_result(\n",
    "            test(\n",
    "                KMeansIndex, d=d, layers=layers, nprobe=nprobe, m=5, U=0.85))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_result(\n",
    "    test(\n",
    "        faiss.IndexFlatIP, d=d))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
