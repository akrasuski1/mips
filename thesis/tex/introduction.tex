The aim of this thesis is to describe a library for fast, approximate \textit{Maximum Inner Product Search} (MIPS),
which we created as part of our dissertation. 

The goal of this work was to provide a set of tools that would help machine learning developers and practitioners create faster, 
more scalable machine learning models.

In MIPS we are usually given a big set $S$ of vectors (also called a database) and a set of queries
(which are technically vectors too). Single query is denoted by $q$.
These vectors are multidimensional and number of dimensions can be in range of hundreds or thousands.
Every vector from database and every query represent an object with a number of features equal to number of dimensions.
The essence of MIPS is for each query to retrieve a fixed number (denoted by $k$)
of objects from database that resemble the query most.
Values of $k$ are typically ranging from $5$ to $100$.
The retrieval process is also called querying or prediction.

All vectors should be prepared in such a way that the higher inner product between them is, the more similar they are
 --- inner product is the similarity metric here. Having said that, the goal is to find $y$ complying with the condition
\[ y = \argmax_{x \in S} q^T x \]

Unfortunately, when one has to query against hundreds of thousands of vectors,
a linear search time can become prohibitively expensive.
In other words multiplicating query and every database vector may not be feasible in practical applications.
To counter that, proposals we made in several articles to build an \textit{index} for prediction speedup.
Index is essentially a specific data structure built by processing data from database (the phase also called training).
The most important feature of the index is short prediction time, training can last much longer however.
It is not expected that the index will return exact result --- it can be approximate.
In fact there is a tradeoff between speed and precision, which will be shown further in the thesis.

Problems requiring MIPS naturally arise in many machine learning models, for example in
classification problems with large output spaces, when a linear models or deep neural networks are used.

The library we built aims to deliver indexes, based on algorithms proposed in three articles,
designed to efficiently retrieve a set of approximate results.

Additionally, we wanted the algorithms to not only offer high performance, but also to be easy-to-use. We therefore
focused on providing a set of wrappers around a range of machine learning libraries, that allow users to 
speed up their models without ever touching any of the algorithms indexes rely on. Consequently,
these wrappers can be used as drop-in replacements for a number of models in Python machine learning ecosystem.
We show some examples of how this library can be used in practice,
as well as detailed experiments measuring the speed and accuracy of our algorithms.

The rest of this thesis is structured as follows.
Second chapter is dedicated to theoretical description of algorithms aiming to solve MIPS.
Third chapter describes implementation details of written software.
Fourth chapter presents experiments' results.
Fifth chapter concludes the thesis.
There is appendix at the end which describes how to run our library.

Marcin Elantkowski wrote wrappers translating C++ indexes to Python, prepared data using his fork of FastText library, adapted the code so it could be used from Pytorch and ran final tests on Amazon Web Services.

Adam Krasuski refactored earlier C++ code, implemented faiss interface and additional optimizations.

Agnieszka Lipska implemented first version of quantization algorithm, implemented faiss interface and adapted the code to use it from Scikit-learn.

Franciszek Walkowiak implemented naive versions of ALSH and hierarchical \mbox{k-means} and conducted preliminary tests on a personal computer.
