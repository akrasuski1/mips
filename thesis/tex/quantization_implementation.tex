Database is loaded to \texttt{FlatMatrix} and vectors are permuted randomly.
Subspaces (sets of vector parts) are implemented as a \texttt{std::vector} of \texttt{FlatMatrix}.
The width of \texttt{FlatMatrix} is determined keeping in mind that original width may not be
divisible by required number of subspaces --- if it happens, the last subspace has less dimensions.
Data is then accordingly copied to elements of mentioned \texttt{std::vector}.
Subsequently, the same flat $K$-means procedure which forms the base of hierarchical $K$-means
is performed on every subspace. It returns the most important part of index:
a structure comprising of \texttt{FlatMatrix} to store centroids and a \texttt{std::vector}
containing assignments of points to centroids.

Before searching the index, queries are likewise loaded to \texttt{FlatMatrix}, permuted and divided into subspaces.
Prediction method operates on two vectors created before, having size equal to number of subspaces:
vector of sets of query parts and a vector of sets of $K$-means centroids for every subspace.
Next, another \texttt{FlatMatrix} of inner products between query parts and $K$-means centroids
is computed and remembered.
The products of centroids assigned to vector in each part and query parts are summed and give vector score.
Such computed scores are saved in a \texttt{std::vector} of pairs --- vector index and its score.
This vector of pairs is sorted by score, truncated to demanded size of $k$ best vectors and their indices returned.
