In MIPS we are usually given a large set $S$ of vectors (also called a database) and a set of queries
(which are vectors as well). Single query is denoted by $q$.
These vectors are often high dimensional --- the number of dimensions can be in range of hundreds or thousands.
Every vector from database and every query represents an object with a number of features equal to the number of dimensions.
The essence of MIPS is for each query to retrieve a fixed number (denoted by $k$)
of objects from database that resemble the query most.
Values of $k$ are typically ranging from $5$ to $100$.
The retrieval process is also called querying or prediction.

All vectors should be prepared in such a way that the higher inner product between them is, the more similar they are
 --- inner product is the similarity metric here. Having said that, the goal is to find $y$ complying with the condition
\[ y = \argmax_{x \in S} q^T x \]
\remark{Problem należy tak sformalizować, aby był on zgodny z Waszym opisem, w którym szukany jest zbiór obiektów, a nie pojedynczy $y$}


The MIPS problem is closely related to Maximum Cosine
Similarity Search (MCSS) and Nearest Neighbour Search (NNS).
The goal in MIPS is to find a vector maximizing the inner product with the query. In turn, 
in MCSS we maximize the cosine similarity between the vector and the query (or equivalently,
minimize the angle between the vector and the query), and in NNS we minimize the distance between the vector and the query. All three problems are
equivalent if all vectors are of unit length. In general, this is not a case.
There exist, however, a couple of known ways
of transforming data and query vectors in order to transform the MIPS problem to MCSS or NNS in the transformed space. We compare two such 
transformations, one introduced by Shrivastava and Li \cite{alsh}, and the second by
Neyshabur and Srebro \cite{neyshabur}.

The first transformation has two parameters: $m$ and $0 < U < 1$. All queries
are first normalized, and all vectors divided by the same number such that
their norm is smaller than $U$. Neither of these changes
$$ \argmin_{i}\ x_i \cdot q\,.$$ 
Then, the following transformations are applied to data
and query vectors:\footnote{In other papers, the $\frac{1}{2}$ fractions are
instead moved to $x'$, for example $\frac{1}{2} - ||x||^2$, leaving extra
query components equal to 0. This does not change the analysis though.}
\begin{eqnarray*}
x' & = & [x, ||x||^2, ||x||^4, \cdots, ||x||^{2^m}] \,, \\
q' & = & [q, \frac{1}{2}, \frac{1}{2}, \dots, \frac{1}{2}] \,. 
\end{eqnarray*}
Both transformations extend vectors by $m$ positions. It can be shown that
the solution to NNS problem in this space is the same as solution to the original
MIPS problem, as long as $m$ is sufficiently large:
\begin{eqnarray*}
||x' - q'||^2 & = & ||x - q||^2 +
\left (||x||^2 - \frac{1}{2} \right )^2 + \left (||x||^4 - \frac{1}{2} \right )^2 + \dots + 
\left (||x||^{2^m} - \frac{1}{2} \right )^2 \\
& = & ||x||^2 + ||q||^2 - 2 q \cdot x + ||x||^{2^{m+1}} + \frac{m}{4} - ||x||^2 \\
& = & 1 + \frac{m}{4} - 2 q \cdot x + ||x||^{2^{m+1}} \,.
\end{eqnarray*}
\remark{Co się dzieje z $||q||^2$?}

In the above $1 + \frac{m}{4} $ is a constant, so it does not change the NNS solution. Similarly  the last term, 
$||x||^{2^{m+1}}$,  which quickly vanishes as $m \to \infty$, so it can be skipped
as an approximation. Shrivastava suggests using $m \ge 3$ for good results.
This leaves just the $ - 2 q \cdot x $ term, which is, up to a multiplicative
constant, the metric optimized in MIPS.
Thus:
$$
\argmax_{i}\ x_i \cdot q \simeq \argmin_{i}\ ||x' - q'||
$$

Neyshabur simplifies the augmentation significantly. Here, queries are also
normalized, and vectors scaled such that they are within unit sphere. The
transformation is then:
\begin{eqnarray*}
x' & = & [x, \sqrt{1 - ||x||^2}] \\
q' & = &  [q, 0] \,.
\end{eqnarray*}
The inner product of modified vectors is $x' \cdot q' = x \cdot q$, i.e., equal
to the original inner product. MIPS on transformed vectors has thus the same
solution as MIPS on original ones. There is however a useful property of this
augmentation: it makes all vectors' norms equal to one: 
\begin{eqnarray*}
||q'|| & = & ||q|| = 1 \\
||x'||^2 & = & ||x||^2 + \sqrt{1 - ||x||^2}^2 = ||x||^2 + 1 - ||x||^2 = 1 \,. 
\end{eqnarray*}
That means new MIPS problem is equivalent to MCSS and NNS in the transformed
space.

Hierarchical $K$-means and ALSH approximations for MIPS problem may use one
of these two augmentations to improve the results. In our implementation,
algorithms are parametrized by the type of the transformation used: Shrivastava,
Neyshabur, or no transformation as a baseline. \remark{Zmieńcie nazwy tych transformacji, ponieważ w przypadku obydwóch publikacji jest więcej niż jeden autor}
